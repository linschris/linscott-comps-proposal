@techreport {Stanford2017,
   author = {Arthurs, N. and Birnbaum, S. and Gruver, N.},
   title = {Selecting Youtube Video Thumbnails via Convolutional Neural Networks},
   institution = {Stanford},
   url ={http://cs231n.stanford.edu/reports/2017/pdfs/710.pdf},
   year = {2017},
}
@techreport {Stanford2021,
   author = {Chen, Y. and Wang, Y. and Tan, R.},
   title = {Classifying YouTube Videos by Thumbnail},
   institution = {Stanford},
   url = {http://cs230.stanford.edu/projects_fall_2021/reports/103085886.pdf},
   year = {2021},
}
@techreport {Adrakatti2016,
    author = {Adrakatti, A. and Wodeyar, R. and Mulla, K.},
    title = {Search by Image: A Novel Approach to Content Based Image Retrieval System},
    url = {https://www.researchgate.net/publication/305683970_Search_by_Image_A_Novel_Approach_to_Content_Based_Image_Retrieval_System},
    year = {2016},
}
@article {PrasadClustering,
   author = {Sunit Prasad},
   title = {Different Types of Clustering Methods and Applications},
   url = {https://www.analytixlabs.co.in/blog/types-of-clustering-algorithms/#sub1},
}
@article {C3Clustering,
   author={C3AI},
   title={Clustering},
   url={https://c3.ai/glossary/data-science/clustering/},
}
@techreport {Kavitha2020,
   author = {Kavitha, P. K. and Saraswathi, Vidhya P.},
   title = {Content based satellite image retrieval system using fuzzy clustering},
   url = {https://link.springer.com/article/10.1007/s12652-020-02064-1},
   year = {2020},
}
@techreport {Schwammle2010,
   author = {Schwammle, V. and Jensen O.},
   title = {A simple and fast method to determine the parameters for fuzzy c–means cluster analysis},
   url = {https://academic.oup.com/bioinformatics/article/26/22/2841/227572},
   year = {2010},
}
@techreport {Moore2018,
   author = {Moore D. and Mamrosh J.},
   title = {Using Google Reverse Image Search to Decipher Biological Images},
   url = {https://currentprotocols.onlinelibrary.wiley.com/doi/10.1002/0471142727.mb1913s111},
   year = {2018},
}
@article{Mittal2021,
	title = {A comprehensive survey of image segmentation: clustering methods, performance parameters, and benchmark datasets},
	issn = {1380-7501, 1573-7721},
	shorttitle = {A comprehensive survey of image segmentation},
	url = {http://link.springer.com/10.1007/s11042-021-10594-9},
	doi = {10.1007/s11042-021-10594-9},
	abstract = {Image segmentation is an essential phase of computer vision in which useful information is extracted from an image that can range from finding objects while moving across a room to detect abnormalities in a medical image. As image pixels are generally unlabelled, the commonly used approach for the same is clustering. This paper reviews various existing clustering based image segmentation methods. Two main clustering methods have been surveyed, namely hierarchical and partitional based clustering methods. As partitional clustering is computationally better, further study is done in the perspective of methods belonging to this class. Further, literature bifurcates the partitional based clustering methods into three categories, namely K-means based methods, histogram-based methods, and meta-heuristic based methods. The survey of various performance parameters for the quantitative evaluation of segmentation results is also included. Further, the publicly available benchmark datasets for image-segmentation are briefed.},
	language = {en},
	urldate = {2022-04-26},
	journal = {Multimedia Tools and Applications},
	author = {Mittal, Himanshu and Pandey, Avinash Chandra and Saraswat, Mukesh and Kumar, Sumit and Pal, Raju and Modwel, Garv},
	month = feb,
	year = {2021},
	file = {Mittal et al. - 2021 - A comprehensive survey of image segmentation clus.pdf:/Users/lchris/Zotero/storage/E2C2JD4K/Mittal et al. - 2021 - A comprehensive survey of image segmentation clus.pdf:application/pdf},
}

@misc{Lavrenko2014,
	title = {Clustering 9: image representation},
	shorttitle = {Clustering 9},
	url = {https://www.youtube.com/watch?v=yDi2uX5tihc},
	abstract = {Full lecture: http://bit.ly/K-means 
Clustering can be used to represent natural images for the purpose of object detection or image tagging. We partition an image using a rectangular grid, compute a feature vector for each cell, and use K-means to assign each vector to a cluster. The clusters can then be used as discrete attributes for representing the entire image (this is known as a bag-of-visual-terms representation).},
	urldate = {2022-04-29},
	author = {{Victor Lavrenko}},
	month = jan,
	year = {2014},
}

@misc{Khandelwal2018,
	title = {Convolutional {Neural} {Network}({CNN}) {Simplified}},
	url = {https://medium.datadriveninvestor.com/convolutional-neural-network-cnn-simplified-ecafd4ee52c5},
	abstract = {Interested in understanding how some of the apps today classify images of your family and friends and have basics of machine learning then…},
	language = {en},
	urldate = {2022-04-29},
	journal = {Medium},
	author = {Khandelwal, Renu},
	month = oct,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/FHY9E52P/convolutional-neural-network-cnn-simplified-ecafd4ee52c5.html:text/html},
}

@misc{Arc2018,
	title = {Convolutional {Neural} {Network}},
	url = {https://towardsdatascience.com/convolutional-neural-network-17fb77e76c05},
	abstract = {In this article, we will see what are Convolutional Neural Networks, ConvNets in short. ConvNets are the superheroes that took working…},
	language = {en},
	urldate = {2022-04-29},
	journal = {Medium},
	author = {Arc},
	month = dec,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/7CIA8G34/convolutional-neural-network-17fb77e76c05.html:text/html},
}
@misc{Jordan2018,
	title = {Evaluating image segmentation models.},
	url = {https://www.jeremyjordan.me/evaluating-image-segmentation-models/},
	abstract = {When evaluating a standard machine learning model, we usually classify our predictions into four categories: true positives, false positives, true negatives, and false negatives. However, for the dense prediction task of image segmentation, it's not immediately clear what counts as a \&quot;true positive\&quot; and, more generally, how we},
	language = {en},
	urldate = {2022-04-29},
	journal = {Jeremy Jordan},
	month = may,
	year = {2018},
	file = {Snapshot:/Users/lchris/Zotero/storage/3NHAXKEH/evaluating-image-segmentation-models.html:text/html},
}
@article{Zhang2019,
	title = {A {Robust} {Bias}-{Correction} {Fuzzy} {Weighted} {C}-{Ordered}-{Means} {Clustering} {Algorithm}},
	volume = {2019},
	issn = {1024-123X},
	url = {https://www.hindawi.com/journals/mpe/2019/5984649/},
	doi = {10.1155/2019/5984649},
	abstract = {This paper proposes a modified fuzzy C-means (FCM) algorithm, which combines the local spatial information and the typicality of pixel data in a new fuzzy way. This new algorithm is called bias-correction fuzzy weighted C-ordered-means (BFWCOM) clustering algorithm. It can overcome the shortcomings of the existing FCM algorithm and improve clustering performance. The primary task of BFWCOM is the use of fuzzy local similarity measures (space and grayscale). Meanwhile, this new algorithm adds a typical analysis of data attributes to membership, in order to ensure noise insensitivity and the preservation of image details. Secondly, the local convergence of the proposed algorithm is mathematically proved, providing a theoretical preparation for fuzzy classification. Finally, data classification and real image experiments show the effectiveness of BFWCOM clustering algorithm, having a strong denoising and robust effect on noise images.},
	language = {en},
	urldate = {2022-04-29},
	journal = {Mathematical Problems in Engineering},
	author = {Zhang, Wenyuan and Huang, Tianyu and Chen, Jun},
	month = jun,
	year = {2019},
	note = {Publisher: Hindawi},
	pages = {e5984649},
	file = {Full Text PDF:/Users/lchris/Zotero/storage/YI3WIKIJ/Zhang et al. - 2019 - A Robust Bias-Correction Fuzzy Weighted C-Ordered-.pdf:application/pdf;Snapshot:/Users/lchris/Zotero/storage/KIJN89VY/5984649.html:text/html},
}
@article{Fuchs2018,
	title = {The {Dangers} of {Human}-{Like} {Bias} in {Machine}-{Learning} {Algorithms}},
	volume = {2},
	url = {https://scholarsmine.mst.edu/peer2peer/vol2/iss1/1},
	number = {1},
	journal = {Missouri S\&T’s Peer to Peer},
	author = {Fuchs, Daniel},
	month = may,
	year = {2018},
}
@article {C3Clustering,
   author = {C3AI},
   title = {Clustering},
   url = {https://c3.ai/glossary/data-science/clustering/},
}
@article{Yu2020,
	title = {One {Algorithm} {May} {Not} {Fit} {All}: {How} {Selection} {Bias} {Affects} {Machine}                    {Learning} {Performance}},
	volume = {40},
	issn = {0271-5333},
	shorttitle = {One {Algorithm} {May} {Not} {Fit} {All}},
	url = {https://pubs.rsna.org/doi/full/10.1148/rg.2020200040},
	doi = {10.1148/rg.2020200040},
	abstract = {Machine learning (ML) algorithms have demonstrated high diagnostic accuracy in identifying and categorizing disease on radiologic images. Despite the results of initial research studies that report ML algorithm diagnostic accuracy similar to or exceeding that of radiologists, the results are less impressive when the algorithms are installed at new hospitals and are presented with new images. This phenomenon is potentially the result of selection bias in the data that were used to develop the ML algorithm. Selection bias has long been described by clinical epidemiologists as a key consideration when designing a clinical research study, but this concept has largely been unaddressed in the medical imaging ML literature. The authors discuss the importance of selection bias and its relevance to ML algorithm development to prepare the radiologist to critically evaluate ML literature for potential selection bias and understand how it might affect the applicability of ML algorithms in real clinical environments. ©RSNA, 2020},
	number = {7},
	urldate = {2022-04-06},
	journal = {RadioGraphics},
	author = {Yu, Alice                        C. and Eng, John},
	month = nov,
	year = {2020},
	note = {Publisher: Radiological Society of North America},
	pages = {1932--1937},
	file = {Full Text PDF:/Users/lchris/Zotero/storage/YMQSH2IR/Yu and Eng - 2020 - One Algorithm May Not Fit All How Selection Bias .pdf:application/pdf},
}
@misc{Warrick2020,
	title = {{YouTube}-{8M} {Dataset}},
	url = {https://medium.com/google-cloud/youtube-8m-dataset-c2ee9c79d136},
	abstract = {YouTube-8M is a project that was developed by Google AI/Research in 2016 to drive innovations and advancement in computer vision…},
	language = {en},
	urldate = {2022-04-16},
	journal = {Google Cloud - Community},
	author = {Warrick},
	month = may,
	year = {2020},
	file = {Snapshot:/Users/lchris/Zotero/storage/UM69XR6W/youtube-8m-dataset-c2ee9c79d136.html:text/html},
}
@misc{googleYT8M,
	title = {{YouTube}-{8M}: {A} {Large} and {Diverse} {Labeled} {Video} {Dataset} for {Video} {Understanding} {Research}},
	url = {https://research.google.com/youtube8m/},
	urldate = {2022-04-16},
	file = {YouTube-8M\: A Large and Diverse Labeled Video Dataset for Video Understanding Research:/Users/lchris/Zotero/storage/FPJ9NISZ/youtube8m.html:text/html},
}
@misc{fairness2017,
	title = {Machines are getting schooled on fairness},
	url = {https://www.sciencenews.org/article/machines-are-getting-schooled-fairness},
	abstract = {Machine-learning programs are introducing biases that may harm job seekers, loan applicants and more.},
	language = {en-US},
	urldate = {2022-04-15},
	journal = {Science News},
	month = sep,
	year = {2017},
	file = {Snapshot:/Users/lchris/Zotero/storage/S7XRXRAK/machines-are-getting-schooled-fairness.html:text/html},
}
@article{Rajkomar2018,
	title = {Ensuring {Fairness} in {Machine} {Learning} to {Advance} {Health} {Equity}},
	volume = {169},
	issn = {0003-4819},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6594166/},
	doi = {10.7326/M18-1990},
	abstract = {Machine learning is used increasingly in clinical care to improve diagnosis, treatment selection, and health system efficiency. Because machine-learning models learn from historically collected data, populations that have experienced human and structural biases in the past—called protected groups—are vulnerable to harm by incorrect predictions or withholding of resources. This article describes how model design, biases in data, and the interactions of model predictions with clinicians and patients may exacerbate health care disparities. Rather than simply guarding against these harms passively, machine-learning systems should be used proactively to advance health equity. For that goal to be achieved, principles of distributive justice must be incorporated into model design, deployment, and evaluation. The article describes several technical implementations of distributive justice—specifically those that ensure equality in patient outcomes, performance, and resource allocation—and guides clinicians as to when they should prioritize each principle. Machine learning is providing increasingly sophisticated decision support and population-level monitoring, and it should encode principles of justice to ensure that models benefit all patients.},
	number = {12},
	urldate = {2022-04-15},
	journal = {Annals of internal medicine},
	author = {Rajkomar, Alvin and Hardt, Michaela and Howell, Michael D. and Corrado, Greg and Chin, Marshall H.},
	month = dec,
	year = {2018},
	pmid = {30508424},
	pmcid = {PMC6594166},
	pages = {866--872},
	file = {PubMed Central Full Text PDF:/Users/lchris/Zotero/storage/APEYD9CU/Rajkomar et al. - 2018 - Ensuring Fairness in Machine Learning to Advance H.pdf:application/pdf},
}
@misc{Zippia2021,
	title = {Content {Creator} {Demographics} and {Statistics} [2022]: {Number} {Of} {Content} {Creators} {In} {The} {US}},
	shorttitle = {Content {Creator} {Demographics} and {Statistics} [2022]},
	url = {https://www.zippia.com/content-creator-jobs/demographics/},
	abstract = {What are the US demographics for Content Creators? Learn more about 2022 demographics based on factors such as age, race, sex, salary and location.},
	language = {en-US},
	urldate = {2022-04-15},
	month = jan,
	year = {2021},
	file = {Snapshot:/Users/lchris/Zotero/storage/5PKPX8ML/demographics.html:text/html},
}
@article{Hellstrom2020,
	title = {Bias in {Machine} {Learning} -- {What} is it {Good} for?},
	url = {http://arxiv.org/abs/2004.00686},
	abstract = {In public media as well as in scientific publications, the term {\textbackslash}emph\{bias\} is used in conjunction with machine learning in many different contexts, and with many different meanings. This paper proposes a taxonomy of these different meanings, terminology, and definitions by surveying the, primarily scientific, literature on machine learning. In some cases, we suggest extensions and modifications to promote a clear terminology and completeness. The survey is followed by an analysis and discussion on how different types of biases are connected and depend on each other. We conclude that there is a complex relation between bias occurring in the machine learning pipeline that leads to a model, and the eventual bias of the model (which is typically related to social discrimination). The former bias may or may not influence the latter, in a sometimes bad, and sometime good way.},
	urldate = {2022-04-16},
	journal = {arXiv:2004.00686 [cs]},
	author = {Hellström, Thomas and Dignum, Virginia and Bensch, Suna},
	month = sep,
	year = {2020},
	note = {arXiv: 2004.00686},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/9R38RJYA/Hellström et al. - 2020 - Bias in Machine Learning -- What is it Good for.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/UDTYA9XB/2004.html:text/html},
}
@article{Hu2019,
	title = {Should {Researchers} {Be} {Allowed} to {Use} {YouTube} {Videos} and {Tweets}?},
	issn = {1091-2339},
	url = {https://slate.com/technology/2019/06/youtube-twitter-irb-human-subjects-research-social-media-mining.html},
	abstract = {A new paper used YouTubers’ voices to guess what they looked like. We’re going to see more of this.},
	language = {en-US},
	urldate = {2022-04-16},
	journal = {Slate},
	author = {Hu, Jane C.},
	month = jun,
	year = {2019},
	keywords = {ethics, privacy, research, social-media, youtube},
	file = {Snapshot:/Users/lchris/Zotero/storage/2WURLEE9/youtube-twitter-irb-human-subjects-research-social-media-mining.html:text/html},
}
@misc{CrashCourseABias,
	title = {Algorithmic {Bias} and {Fairness}: {Crash} {Course} {AI} \#18},
	shorttitle = {Algorithmic {Bias} and {Fairness}},
	url = {https://www.youtube.com/watch?v=gV0_raKR2UQ},
	abstract = {Check out my collab with "Above the Noise" about Deepfakes: https://www.youtube.com/watch?v=Ro8b6...
Today, we're going to talk about five common types of algorithmic bias we should pay attention to: data that reflects existing biases, unbalanced classes in training data, data that doesn't capture the right value, data that is amplified by feedback loops, and malicious data. Now bias itself isn't necessarily a terrible thing, our brains often use it to take shortcuts by finding patterns, but bias can become a problem if we don't acknowledge exceptions to patterns or if we allow it to discriminate.},
	urldate = {2022-04-16},
	author = {{CrashCourse}},
	month = dec,
	year = {2019},
}
@misc{HootSuite2022,
	title = {23 {YouTube} {Stats} {That} {Matter} to {Marketers} in 2022},
	url = {https://blog.hootsuite.com/youtube-stats-marketers/},
	abstract = {Here are the most important YouTube statistics marketers should know for 2022. Some of them are surprising!},
	language = {en-US},
	urldate = {2022-04-14},
	journal = {Social Media Marketing \& Management Dashboard},
	month = feb,
	year = {2022},
	file = {Snapshot:/Users/lchris/Zotero/storage/RE6DDTCL/youtube-stats-marketers.html:text/html},
}
@misc{Muller2021,
	title = {Clickbait is {Unreasonably} {Effective}},
	url = {https://www.youtube.com/watch?v=S2xHZPH5Sng},
	abstract = {The title and thumbnail play a huge role in a video's success or failure.
Written by Derek Muller
Animation by Iván Tello
Filmed by Derek Muller and Emily Zhang
Additional video supplied by Getty Images 
Produced by Derek Muller, Emily Zhang and Petr Lebedev},
	urldate = {2022-04-16},
	author = {Derek Muller},
	month = aug,
	year = {2021},
}
@misc{GeeksForGeeks2019,
	title = {{ML} {\textbar} {Fuzzy} {Clustering}},
	url = {https://www.geeksforgeeks.org/ml-fuzzy-clustering/},
	abstract = {A Computer Science portal for geeks. It contains well written, well thought and well explained computer science and programming articles, quizzes and practice/competitive programming/company interview Questions.},
	language = {en-us},
	urldate = {2022-04-16},
	journal = {GeeksforGeeks},
	month = sep,
	year = {2019},
	note = {Section: Articles},
	file = {Snapshot:/Users/lchris/Zotero/storage/HYRJGSTH/ml-fuzzy-clustering.html:text/html},
}
@misc{YTAddingThumbnails,
	title = {Add video thumbnails on {YouTube} - {YouTube} {Help}},
	url = {https://support.google.com/youtube/answer/72431?hl=en},
	urldate = {2022-04-16},
	file = {Add video thumbnails on YouTube - YouTube Help:/Users/lchris/Zotero/storage/N69ABDVL/72431.html:text/html},
}
@misc{YTFairUse,
	title = {{YouTube} {Copyright} \& {Fair} {Use} {Policies} - {How} {YouTube} {Works}},
	url = {https://www.youtube.com/howyoutubeworks/policies/copyright/},
	abstract = {Everyone has access to YouTube’s Copyright Management Tools, which gives rights holders control of their copyrighted material on YouTube.},
	language = {en},
	urldate = {2022-04-16},
	journal = {YouTube Copyright \& Fair Use Policies - How YouTube Works},
	file = {Snapshot:/Users/lchris/Zotero/storage/F97HANIF/copyright.html:text/html},
}
@article{Wang2020,
	title = {Decorrelated {Clustering} with {Data} {Selection} {Bias}},
	url = {http://arxiv.org/abs/2006.15874},
	abstract = {Most of existing clustering algorithms are proposed without considering the selection bias in data. In many real applications, however, one cannot guarantee the data is unbiased. Selection bias might bring the unexpected correlation between features and ignoring those unexpected correlations will hurt the performance of clustering algorithms. Therefore, how to remove those unexpected correlations induced by selection bias is extremely important yet largely unexplored for clustering. In this paper, we propose a novel Decorrelation regularized K-Means algorithm (DCKM) for clustering with data selection bias. Specifically, the decorrelation regularizer aims to learn the global sample weights which are capable of balancing the sample distribution, so as to remove unexpected correlations among features. Meanwhile, the learned weights are combined with k-means, which makes the reweighted k-means cluster on the inherent data distribution without unexpected correlation influence. Moreover, we derive the updating rules to effectively infer the parameters in DCKM. Extensive experiments results on real world datasets well demonstrate that our DCKM algorithm achieves significant performance gains, indicating the necessity of removing unexpected feature correlations induced by selection bias when clustering.},
	urldate = {2022-04-16},
	journal = {arXiv:2006.15874 [cs, stat]},
	author = {Wang, Xiao and Fan, Shaohua and Kuang, Kun and Shi, Chuan and Liu, Jiawei and Wang, Bai},
	month = jul,
	year = {2020},
	note = {arXiv: 2006.15874},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: Accepted by main track of IJCAI2020;SOLE copyright holder is IJCAI (international Joint Conferences on Artificial Intelligence), all rights reserved},
	file = {arXiv Fulltext PDF:/Users/lchris/Zotero/storage/F58HXMJT/Wang et al. - 2020 - Decorrelated Clustering with Data Selection Bias.pdf:application/pdf;arXiv.org Snapshot:/Users/lchris/Zotero/storage/53T3UXUK/2006.html:text/html},
}